predicting change using software metrics a review 2015 ieee software change prediction deals with identifying the classes that are prone to changes during the early phases of software development life cycle prediction of change prone classes leads to higher quality maintainable software with low cost this study reports a systematic review of change prediction studies published in journals and conference proceedings this review will help researchers and practitioners to examine the previous studies from different viewpoints metrics data analysis techniques datasets and experimental results perspectives besides this the research questions formulated in the review allow us to identify gaps in the current technology the key findings of the review are i less use of method level metrics machine learning methods and commercial datasets ii inappropriate use of performance measures and statistical tests iii lack of use of feature reduction techniques iv lack of risk indicators used for identifying change prone classes and v inappropriate use of validation methods change prediction empirical validation machine learning software maintenance software metrics dynamic metrics are superior than static metrics in maintainability prediction an empirical case study 2015 ieee software metrics help us to make meaningful estimates for software products and guide us in taking managerial and technical decisions like budget planning cost estimation quality assurance testing software debugging software performance optimization and optimal personnel task assignments many design metrics have proposed in literature to measure various constructs of object oriented oo paradigm such as class coupling cohesion inheritance information hiding and polymorphism and use them further in determining the various aspects of software quality however the use of conventional static metrics have found to be inadequate for modern oo software due to the presence of run time polymorphism templates class template methods dynamic binding and some code left unexecuted due to specific input conditions this gap gave a cue to focus on the use of dynamic metrics instead of traditional static metrics to capture the software characteristics and further deploy them for maintainability predictions as the dynamic metrics are more precise in capturing the execution behavior of the software system in the current empirical investigation with the use of open source code we validate and verify the superiority of dynamic metrics over static metrics four machine learning models are used for making the prediction model while training is performed simultaneously using static as well as dynamic metric suite the results are analyzed using prevalent prediction accuracy measures which indicate that predictive capability of dynamic metrics is more concise than static metrics irrespective of any machine learning prediction model results of this would be helpful to practitioners as they can use the dynamic metrics in maintainability prediction in order to achieve precise planning of resource allocation dynamic metrics machine learning software maintainability prediction software quality static metrics mining system logs to learn error predictors a case study of a telemetry system 2014 springer science business media new york predicting system failures can be of great benefit to managers that get a better command over system performance data that systems generate in the form of logs is a valuable source of information to predict system reliability as such there is an increasing demand of tools to mine logs and provide accurate predictions however interpreting information in logs poses some challenges this study discusses how to effectively mining sequences of logs and provide correct predictions the approach integrates different machine learning techniques to control for data brittleness provide accuracy of model selection and validation and increase robustness of classification results we apply the proposed approach to log sequences of 25 different applications of a software system for telemetry and performance of cars on this system we discuss the ability of three well known support vector machines multilayer perceptron radial basis function and linear kernels to fit and predict defective log sequences our results show that a good analysis strategy provides stable accurate predictions such strategy must at least require high fitting ability of models used for prediction we demonstrate that such models give excellent predictions both on individual applications e g 1 false positive rate 94 true positive rate and 95 precision and across system applications on average 9 false positive rate 78 true positive rate and 95 precision we also show that these results are similarly achieved for different degree of sequence defectiveness to show how good are our results we compare them with recent studies in system log analysis we finally provide some recommendations that we draw reflecting on our study classification and prediction of defective log sequences data mining information gain log analysis software maintenance system logs a proposed new model for maintainability index of open source software 2014 ieee software metrics play a key role in measuring attributes that are important for the success of a software project measurements of these metrics tell us various key aspects of system this in turn supports knowledgeable decision making by which we can enhance the quality of system maintenance is a process of revisions or corrections made to software systems after their first release the key feature of software development is change hence it is important to develop software that is easy to modify and is thus maintainable this paper evaluates the existing oman and hagemeister maintainability index model which calculates maintainability index mi based on cyclomatic complexity lines of code and halsted volume for this purpose software metric datasets of lucene which is open source software of 163085 lines of code are used and it is shown that the existing oman and hagemeister maintainability index mode model is not a good a predictor of maintainability a new maintainability index model is proposed with a new set of predictor metrics the new proposed model is a marked improvement over the existing oman and hagemeister maintainability index model the coefficient of determination r 2 of the new proposed maintainability model is 0 984 and correlation coefficient r is 0 992 as compared to the oman and hagemeister model whose correlation coefficient r is 0 320 maintainability effort maintainability index maintenance metrics software maintainability prediction predictive modeling for shelf life estimation of sunflower oil blended with oleoresin rosemary rosmarinus officinalis l and ascorbyl palmitate at low and high temperatures 2014 elsevier ltd the induction period ip of the formation of conjugated dienes ip cdv at low 60°c and ip measured using rancimat at high 100 130°c temperatures were determined as oxidative stability measure osm of sunflower oil so samples blended with oleoresin rosemary rosmarinus officinalis l and ascorbyl palmitate the relationship between osm and compositional parameters peroxide value acid value total polar matter antioxidant capacity and total added antioxidants was established using partial least square pls regression the predicted shelf life at 60°c sl 60 using the pls and rancimat models resulted in the under prediction by 0 02 and 50 22 respectively to overcome the shortcomings of rancimat model a unified model was developed using ip cdv values as a function of ip at 100 130°c which over predicted the sl 60 by 0 08 the unified model estimated the sl 25 with an error of ±3 32 which was comparable to pls ±2 99 and lesser than rancimat ±11 22 models partial least square regression rancimat rosemary rosmarinus officinalis l shelf life prediction sunflower oil efficient and accurate approach for approximate string search in spatial dataset 2015 ieee this paper proposes a new index and method to find strings approximately in spatial databases specifically the task of candidate generation is as follows given a location name with wrong spelling the system finds location in osm dataset which are most similar to that location name which are misspelled an approximate solution is proposed using log linear model which is defined as a conditional probability distribution of a corrected word and a rule set for the correction conditioned on wrong location name an aho corasic tree which is used for storing and applying correction rules referred to as rule index and an aho corasic algorithm which is efficient and gives guarantee to find top k candidates experiment on large real osm dataset demonstrates the accuracy of proposed method upon existing methods aho corasick algorithm approximate string search osm dataset spatial databases maintainability prediction from project metrics data analysis using artificial neural network an interdisciplinary study software maintainability is an important aspect for all software engineering paradigms considering the maintainability a factor influencing the software quality and reliability the estimation can help to improve overall software quality maintainability is an indirect and derived measure which needs to predict using the other direct measures soft computing approaches have been used widely in prediction of software entities the paper analyzes the project history data with the help of artificial neural network and produces the predicted maintainability value of the software module or component from the project metrics data four influencing factors identified and neural network model is built for maintainability prediction the four simple input factors multiple condition count node count percentage comments and total lines of code can be easily calculated from the source code of the module or component of a project the less complexity of the input attributes makes the model more applicable in software industries the ann model is evaluated and validated on history data from three projects the root mean square error value shows the ann as good technique to predict the maintainability from the history data idosi publications 2014 artificial neural network maintainability maintenance prediction quality software metrics smplearner learning to predict software maintainability 2014 springer science business media new york accurate and practical software maintainability prediction enables organizations to effectively manage their maintenance resources and guide maintenance related decision making this paper presents smplearner an automated learning based approach to train maintainability predictors by harvesting the actual average maintenance effort computed from the code change history as well as employing a much richer set of 44 four level hierarchical code metrics collected by static code analysis tools we systematically evaluated smplearner on 150 observations partitioned from releases of eight large scale open source software systems our evaluation showed that smplearner not only outperformed the traditional 4 metric mi model but also the recent learning based maintainability predictors constructed based on single class level metrics demonstrating that single class level metrics were not sufficient for maintainability prediction machine learning maintenance effort software maintainability software metric object oriented class stability prediction a comparison between artificial neural network and support vector machine 2014 king fahd university of petroleum and minerals software stability is an important factor for better software quality stable classes tend to reduce the software maintenance cost and effort therefore achieving class stability is an important quality objective when developing software designers can make better decisions to improve class stability if they can predict it before the fact using some predictors in this paper we investigate the correlation between some available design measurements and class stability over versions and propose a stability prediction model using such available measurements we conducted a set of experiments using artificial neural network ann and support vector machine svm to build different prediction models we compared the accuracy of these prediction models our experiments reveal that ann and svm prediction models are effective in predicting object oriented class stability artificial intelligence class stability prediction software quality using software metrics to estimate the impact of maintenance in the performance of embedded software 2014 ieee this paper proposes a strategy to assist the designer in evaluating the impact of a design choice with respect to the non functional requirements in embedded systems we use several regression models to predict physical metrics from design metrics in order to estimate the impact on performance of software changes in the early stages of its development this prediction can be used both during maintenance and during the first design to compare alternative module decompositions or design changes before implementation such an early estimation allows an efficient design space exploration with no penalty in the development time which are crucial aspects for an embedded system design space exploration embedded systems maintenance regression analysis software metrics a way to predict and evaluate of software maintainability based on machine learning the accurate maintainability prediction and evaluation of software applications can improve the designing management for these applications thus benefiting designing organizations therefore there is considerable research interest in development and application of sophisticated techniques which can be used to build models for both predicting and evaluating software maintainability in this paper we investigate some ideas based on machine learning natural language processing fuzzy logic and systematic model of software maintenance the idea to compute interactive index and the maintainability of software system is useful to study the relation between maintainability prediction and maintainability evaluation in the whole software process an model basing on fuzzy matrix and bp neural network is built up it s approved that there are application value of using this model based on bp neural network to predict and evaluate the software maintainability 2014 trans tech publications switzerland fuzzy matrix machine learning neural network model software maintainability classification model for maintainability prediction 2014 mikyeong park and euyseok hong software maintainability prediction is important because it enables organizations to effectively manage maintenance resources and improve design and coding most studies have concentrated on estimating the number of changes or changed lines of code during maintenance period on the other hand we propose classification models that determine maintainability levels of software units classification model is simple to use and makes it easy for developers to analyze results using widely used classification algorithms we build and evaluate two types of prediction models the experimental results show that decision tree with a cfssubseteval attribute selection method has the best performance in binary classifications and naïve bayesian outperforms others in ternary classifications classification maintainability prediction software maintainability software maintainability prediction by data mining of software code metrics 2014 ieee software maintainability is a key quality attribute that determines the success of a software product since software maintainability is an important attribute of software quality accurate prediction of it can help to improve overall software quality this paper utilizes data mining of some new predictor metrics apart from traditionally used software metrics for predicting maintainability of software systems the prediction models are constructed using static code metric datasets of four different open source software oss lucene jhotdraw jedit and jtreeview lucene contain 385 classes and is of 135241 lines of code loc oss jhotdraw contain 159 classes and is of 21802 loc oss jedit contain 275 classes and is of 104053 loc oss and jtreeview contain 60 classes and is of 11988 loc oss the metrics were collected using two different metrics extraction tools chidamber and kemerer java metric ckjm tool and intellij idea naïve bayes bayes network logistic multilayerperceptron and random forest classifiers are used to identify the software modules that are difficult to maintain random forest models are found to be most useful in software maintainability prediction by data mining of software code metrics as random forest models have higher recall precision and area under curve auc of roc curve data mining software code metrics software maintainability prediction application of group method of data handling model for software maintainability prediction using object oriented systems object oriented methodology has emerged as most prominent in software industry for application development maintenance phase begins once the product is delivered and by software maintainability we mean the ease with which existing software could be modified during maintenance phase we can improve and control software maintainability if we can predict it in the early phases of software life cycle using design metrics predicting the maintainability of any software has become critical with the increasing importance of software maintenance many authors have practiced and proved theoretical validation followed by empirical evaluation using statistical and experimental techniques for evaluating the relevance of any given metrics suite using many models in this paper we have presented an empirical study to evaluate the effectiveness of novel technique called group method of data handling gmdh for the prediction of maintainability over other models although many metrics have been proposed in the literature software design metrics suite proposed by chidamber et al and revised by li et al have been selected for this study two web based customized softwares developed using c language have been used for empirical study source code of old and new versions for both applications were collected and analysed against modifications made in every class the changes were counted in terms of number of lines added deleted or modified in the classes belonging to new version with respect to the classes of old version finally values of metrics were combined with change in order to generate data points hence in this study an attempt has been made to evaluate and examine the effectiveness of prediction models for the purpose of software maintainability using real life web based projects three models using feed forward 3 layer back propagation network ff3lbpn general regression neural network grnn and gmdh are developed and performance of gmdh is compared against two others i e ff3lbpn and grnn with the aid of this empirical analysis we can safely suggest that software professionals can use oo metric suite to predict the maintainability of software using gmdh technique with least error and best precision in an object oriented paradigm 2014 the society for reliability engineering quality and operations management sreqom india and the division of operation and maintenance lulea university of technology sweden empirical validation feed forward 3 layer back propagation network ff3lbpn general regression neural network grnn group method of data handling gmdh software maintainability a metric suite for predicting software maintainability in data intensive applications springer science business media dordrecht 2014 software maintainability is the vital aspect of software quality and defined as the ease with which modifications can be made once the software is delivered tracking the maintenance behaviour of a software product is very complex that is widely acknowledged by the researchers many research studies have empirically validated that the prediction of object oriented software maintainability can be achieved before actual operation of the software using design metrics proposed by chidamber and kemerer c k however the framework and reference architecture in which the software systems are being currently developed have changed dramatically in recent times due to the emergence of data warehouse and data mining field in the prevailing scenario certain deficiencies were discovered when c k metric suite was evaluated for data intensive applications in this study we propose a new metric suite to overcome these deficiencies and redefine the relationship between design metrics with maintainability the proposed metric suite is evaluated analyzed and empirically validated using five proprietary software systems the results show that the proposed metric suite is very effective for maintainability prediction of all software systems in general and for data intensive software systems in particular the proposed metric suite may be significantly helpful to the developers in analyzing the maintainability of data intensive software systems before deploying them data intensive applications empirical validation machine learning prediction models software design metric software maintainability evaluation of quantitative and mining techniques for reducing software maintenance risks 2014 abdelrafe elzamly and burairah hussin software risk is not always avoidable but it is controllable the aim of this paper is to present new techniques that were performed using quantitative and mining techniques to compare the risk management techniques to each of the software maintenance risks to identify and model if they are effective in mitigating the occurrence of each software maintenance risk in software development life cycle the model s accuracy slightly improves in fuzzy multiple regression modelling techniques than or quite equal stepwise multiple regression modelling techniques all models in fuzzy and stepwise acceptable value for mmre less than 0 25 and pred 0 25 greater or than 0 75 is desirable the study has been conducted on a group of software project management successful software project risk management will greatly improve the probability of project success mining techniques mmre pred l quantitative techniques software maintenance project software risk management cross project change prediction using open source projects 2014 ieee predicting the changes in the next release of software during the early phases of software development is gaining wide importance such a prediction helps in allocating the resources appropriately and thus reduces costs associated with software maintenance but predicting the changes using the historical data data of past releases of the software is not always possible due to unavailability of data thus it would be highly advantageous if we can train the model using the data from other projects rather than the same project in this paper we have performed cross project predictions using 12 datasets obtained from three open source apache projects abdera poi and rave in the study cross project predictions include both the inter project different projects and inter version different versions of same projects predictions for cross project predictions we investigated whether the characteristics of the datasets are valuable for selecting the training set for a known testing set we concluded that cross project predictions give high accuracy and the distributional characteristics of the datasets are extremely useful for selecting the appropriate training set besides this within cross project predictions we also examined the accuracy of inter version predictions change prediction cross project inter version prediction machine learning metrics object oriented paradigm electre tri to classify items with respect to maintainability criterion the paper aims to suggest a methodology able to support the analyst in the assessment process of items on the base of a criterion inspired to the maintainability parameter and in the successive assignment phase of the items in the predefined classes the maintainability involves the continuous improvement of a system in order to improve the ability to maintain or improve the reliability of the analyzed system in particular the last one is the probability that a failed system will be restored to specified conditions within a given period of time when maintenance is performed according to prescribed procedures and resources the faced case in this research regards the software maintenance field in which the maintainability can be defined as the probability that a program will be restored to working conditions in a given period of time when it is being changed modified or enhanced furthermore the maintainability can be subdivided into diverse sub criteria as analysability how easy or difficult is to diagnose the system for deficiencies or to identify the parts that need to be modified changeability how easy or difficult is to make adaptations to the system stability how easy or difficult is to keep the system in a consistent state during the modification process testability how easy or difficult is it to test the system after modifications thus with respect to aforementioned sub criteria the present research wants to propose the electre tri method in order to assign the different analyzed items with relation to the maintainability criterion into the different predefined classes with the aim to illustrate the method validity a numerical application is shown with relation to the classification under the maintainability criterion of different modular enterprise resource planning software systems electre tri enterprise resource planning maintenaibility machine learning approaches for predicting software maintainability a fuzzy based transparent model software quality is one of the most important factors for assessing the global competitive position of any software company thus the quantification of the quality parameters and integrating them into the quality models is very essential many attempts have been made to precisely quantify the software quality parameters using various models such as boehm s model mccall s model and iso iec 9126 quality model a major challenge although is that effective quality models should consider two types of knowledge imprecise linguistic knowledge from the experts and precise numerical knowledge from historical data incorporating the experts knowledge poses a constraint on the quality model the model has to be transparent in this study the authorspropose a process for developing fuzzy logic based transparent quality prediction models they applied the process to a case study where mamdani fuzzy inference engine is used to predict software maintainability theycompared the mamdani based model with other machine learning approaches the resultsshow that the mamdani based model is superior to all 2013 the institution of engineering and technology statistical comparison of modelling methods for software maintainability prediction the objective of this paper is statistical comparison of modelling methods for software maintainability prediction the statistical comparison is performed by building software maintainability prediction models using 27 dierent regression and machine learning based algorithms for this purpose software metrics datasets of two dierent commercial object oriented systems are used these systems were developed using an object oriented programming language ada these systems are user interface management system uims and quality evaluation system ques it is shown that dierent measures like mmre rmse pred 0 25 and pred 0 30 calculated on predicted values obtained from leave one out loo cross validation produce very divergent results regarding accuracy of modelling methods therefore the 27 modelling methods are evaluated on the basis of statistical signicance tests the friedman test is used to rank various modelling methods in terms of absolute residual error six out of the ten top ranked modelling methods are common to both uims and ques this indicates that modelling methods for software maintainability predicton are solid and scalable after obtaining ranks pair wise wilcoxon signed rank test is performed wilcoxon sign rank test indicates that the top ranking method in uims data set is significantly superior to only four other modelling methods whereas the top tanking method in ques data set is significantly superior to 11 other modelling methods the performance of instance based learning algorithms ibk and kstar is comparable to modelling methods used in earlier studies c world scientific publishing company machine learning significance tests software maintainability prediction software effort prediction a hyper heuristic decision tree based approach software effort prediction is an important task within software engineering in particular machine learning algorithms have been widely employed to this task bearing in mind their capability of providing accurate predictive models for the analysis of project stakeholders nevertheless none of these algorithms has become the de facto standard for metrics prediction given the particularities of different software projects among these intelligent strategies decision trees and evolutionary algorithms have been continuously employed for software metrics prediction though mostly independent from each other a recent work has proposed evolving decision trees through an evolutionary algorithm and applying the resulting tree in the context of software maintenance effort prediction in this paper we raise the search space level of an evolutionary algorithm by proposing the evolution of a decision tree algorithm instead of the decision tree itself an approach known as hyper heuristic our findings show that the decision tree algorithm automatically generated by a hyper heuristic is capable of statistically outperforming state of the art top down and evolution based decision tree algorithms as well as traditional logistic regression the ability of generating a highly accurate comprehensible predictive model is crucial in software projects considering that it allows the stakeholder to properly manage the team s resources with an improved confidence in the model predictions copyright 2013 acm decision trees evolutionary algorithms head dt hyper heuristics software effort estimation using cbr and cart to predict maintainability of relational database driven software applications background relational database driven software applications have gained significant importance in modern software development given that software maintainability is an important quality attribute predicting these applications maintainability can provide various benefits to software organizations such as adopting a defensive design and more informed resource management aims the aim of this paper is to present the results from employing two well known prediction techniques to estimate the maintainability of relational database driven applications method case based reasoning cbr and classification and regression trees cart were applied to data gathered on 56 software projects from software companies the projects concerned development and or maintenance of relational database driven applications unlike previous studies all variables 28 independent and 1 dependent were measured on a 5 point bi polar scale results results showed that cbr performed slightly better at 76 8 correct predictions in terms of prediction accuracy when compared to cart 67 8 in addition the two important predictors identified were documentation quality and understandability of the applications conclusions the results show that cbr can be used by software companies to formalize and improve their process of maintainability prediction future work involves gathering more data and also employing other prediction techniques copyright 2013 acm case based reasoning classification trees maintainability prediction relational database driven software applications modeling code analyzability at method level in j2ee applications 2013 ieee one of the main reasons for improving code structure is to make the cause of error code easily identified thus developers need an analyzability prediction model to evaluate the analyzability of code in order to locate classes to be improved to identify classes to be improved developers must analyze all methods of classes for finding problem methods therefore analyzability prediction model must be created for calculating analyzability level of method currently j2ee applications are legacy systems and need to be continually maintained hence code analyzability prediction at method level in j2ee application helps developers to know which method should be improved for increasing code understanding and reducing time for finding error causes however there is a lack of analyzability prediction model for j2ee application and existing research works on analyzability prediction model do not focus on method level therefore this paper proposes how to create analyzability prediction model at method level for j2ee applications through ordinal logistic regression analyzability component j2ee maintainability software maintenance software maintainability prediction model based on fuzzy neural network due to the vast deployment of object oriented software in our day to day livings the issue of software maintainability prediction which aims at ameliorating the software design process and planning the amount constrained budget efficiently calls attention to it in this paper a fuzzy neural network fnn based software maintainability prediction model which combines the artificial neural network ann and the fuzzy logic fl is proposed to overcome the innate flaws of fnn a statistical technique e g principle component analysis pca is also used for the sake of computational simplicity the proposed fnn reinforced by pca can effectively reflect the complex relations among independent and dependable variables that is by showing relatively high prediction accuracy the empirical experimental results verify this claim in the sense that with respect to two disparate object oriented software data sets the model built by the proposed method prevails against three other typical counterparts multivariable linear regression mlr ann and support vector regression svr in terms of the prediction accuracy 2012 old city publishing inc fuzzy neural network object oriented software principle component analysis software maintainability prediction towards building method level maintainability models based on expert evaluations the maintainability of software systems is getting more and more attention both from researchers and industrial experts this is due to its direct impact on development costs and reliability of the software many models exist for estimating maintainability by aggregating low level source code metrics however very few of them are able to predict the maintainability on method level even fewer take subjective human opinions into consideration in this paper we present a new approach to create method level maintainability prediction models based on human surveys using regression techniques we performed three different surveys and compared the derived prediction models our regression models were built based on approximately 150000 answers of 268 persons these models were able to estimate the maintainability of methods with a 0 72 correlation and a 0 83 mean absolute error on a continuous 0 10 2012 springer verlag comparative study iso iec 9126 regression analysis software maintainability can we predict types of code changes an empirical analysis there exist many approaches that help in pointing developers to the change prone parts of a software system although beneficial they mostly fall short in providing details of these changes fine grained source code changes scc capture such detailed code changes and their semantics on the statement level these scc can be condition changes interface modifications inserts or deletions of methods and attributes or other kinds of statement changes in this paper we explore prediction models for whether a source file will be affected by a certain type of scc these predictions are computed on the static source code dependency graph and use social network centrality measures and object oriented metrics for that we use change data of the eclipse platform and the azureus 3 project the results show that neural network models can predict categories of scc types furthermore our models can output a list of the potentially change prone files ranked according to their change proneness overall and per change type category 2012 ieee machine learning software maintenance software quality recommending relevant code artifacts for change requests using multiple predictors finding code artifacts affected by a given change request is a time consuming process in large software systems various approaches have been proposed to automate this activity e g based on information retrieval the performance of a particular prediction approach often highly depends on attributes like coding style or writing style of change request thus we propose to use multiple prediction approaches in combination with machine learning first experiments show that machine learning is well suitable to weight different prediction approaches for individual software projects and hence improve prediction performance 2012 ieee recommendation systems software maintenance predicting software maintenance effort through evolutionary based decision trees software effort prediction has been a challenge for researchers throughout the years several approaches for producing predictive models from collected data have been proposed although none has become standard given the specificities of different software projects the most commonly employed strategy for estimating software effort the multivariate linear regression technique has numerous shortcomings though which motivated the exploration of many machine learning techniques among the researched strategies decision trees and evolutionary algorithms have been increasingly employed for software effort prediction though independently in this paper we propose employing an evolutionary algorithm to generate a decision tree tailored to a software effort data set provided by a large worldwide it company our findings show that evolutionarily induced decision trees statistically outperform greedily induced ones as well as traditional logistic regression moreover an evolutionary algorithm with a bias towards comprehensibility can generate trees which are easier to be interpreted by the project stakeholders and that is crucial in order to improve the stakeholder s confidence in the final prediction 2012 acm decision trees evolutionary algorithms legal tree software effort estimation estimating software maintenance effort from use cases an industrial case study software maintenance effort constitutes a major portion of the software lifecycle effort its estimation is vital for successful project planning and strategic resource allocation in this paper we conduct and report an industrial case study in this field the data set was collected from an industrial software process management tool qone formerly softpm the methodology proposed provides corresponding guidance for effort estimation in software evolutionary projects that employ use cases in capturing maintenance requirements and the model constructed using the linear regression analysis and validated by the leave one out cross validation provides an effort prediction for the future maintenance of the project the analysis results indicate that the methodology can be applied at an early stage of the project life cycle and provides a good tradeoff among simplicity early estimating and accuracy in one estimate 2011 ieee effort estimation estimate model requirement elaboration software maintenance use case using data mining techniques for time estimation in software maintenance measuring and estimating are fundamental activities for the success of any project in the software maintenance realm the lack of maturity or even a low level of interest in adopting effective maintenance techniques and related metrics has been pointed out as an important cause for the high costs involved in this paper data mining techniques are applied to provide a sound estimation for the time required to accomplish a maintenance task based on real world data regarding maintenance requests some regression models are built to predict the time required for each maintenance data on the team skill and the maintenance characteristics are mapped into values that predict better time estimations in comparison to the one predicted by the human expert a particular finding from this research is that the time prediction provided by a human expert works as an inductive bias that improves the overall prediction accuracy of the models copyright 2011 inderscience enterprises ltd data mining informal reasoning metrics software maintenance towards an estimation model for software maintenance costs today there is no best practise method available to effectively estimate the maintenance costs of historically grown large scale software landscapes most cost estimation models are either not generalizable due to highly specialized scenarios or too abstract to be implemented in practice in this paper we introduce a multi level approach to create transparency estimate costs realistically based on current spending and establish a method for sustainable cost control at the heart of our approach is the deduction of meaningful indicators for estimating current and future maintenance efforts we present the first version of a statistical cost estimation model being implemented at deutsche post mail as a baseline for contract negotiations with providers 2011 ieee case study cost estimation prediction models regression models software maintenance software measurement using commercial off the shelf business intelligence software tools to support aircraft and automated test system maintenance environments the purpose of this paper is to provide information about the benefits using commercial off the shelf cots business intelligence software tools to support aircraft and automated test system maintenance environments aircraft and automated test system parametric and maintenance warehouse based data can be shared and used for predictive data mining exploitation which will enable better decision support for war fighters and back shop maintenance when utilizing common industry business intelligence predictive modeling processes engineering designers can create initial business intelligence aircraft and automated test system maintenance environment engineering cluster models this is a process of grouping together engineering data that have similar aggregate patterns by using these engineering cluster models produced earlier to develop and build more accurate predictive models predictive algorithms are utilized to make use of the cluster results to improve predictive accuracy common industry business intelligence decision trees and neural network models are developed to determine which algorithm produces the most accurate models as measured by comparing predictions with actual values over the testing set after an initial mining structure and mining model is built specifying the input and predictable attributes the analyst can easily add other mining models cots business intelligence software tools provide for a more cost effective support and predictive role for war fighter support personnel in a time of decreased defense spending having access to applicable engineering data at the time of need will decrease troubleshooting time on production aircraft and back shop maintenance increase the ability of the technical user to better understand the diagnostics reduce ambiguities which drive false removals of system components decrease misallocated spares and maintain increase knowledge management 2010 ieee a quantitative approach to software maintainability prediction software maintainability is one important aspect in the evaluation of software evolution of a software product due to the complexity of tracking maintenance behaviors it is difficult to accurately predict the cost and risk of maintenance after delivery of software products in an attempt to address this issue quantitatively software maintainability is viewed as an inevitable evolution process driven by maintenance behaviors given a health index at the time when a software product are delivered a hidden markov model hmm is used to simulate the maintenance behaviors shown as their possible occurrence probabilities and software metrics is the measurement of the quality of a software product and its measurement results of a product being delivered are combined to form the health index of the product the health index works as a weight on the process of maintenance behavior over time when the occurrence probabilities of maintenance behaviors reach certain number which is reckoned as the indication of the deterioration status of a software product the product can be regarded as being obsolete longer the time better the maintainability would be 2010 ieee hidden markov model software maintainability software metrics studies on the use of keel software for intelligent analyzing of bridge load bearing capacity the goal of this paper is to work out an effective computer method to assess the bridge structure condition that is expressed by means of load bearing parameter considering typical bridge damages in order to find the proper algorithm a survey of available regression methods using the keel software was made keel software is used to assess evolutionary algorithms for common data mining problems selected methods were tested using real data that were provided by experts and achieved results were compared to results given by the mybride expert tool all considered algorithms base either on the neural network or fuzzy rule learning approach first stage of the experiment focused on selecting a group of best methods taking into account mean squared error mse standard deviation stdev and mean response time mrt for each algorithm verified methods use normalized input data where the considered range is the interval 0 1 after this initial selection rbfn cor ga fuzzy gap fuzzy sap and thrift algorithms were promoted for further tests the aim of experiment s second stage was to compare previously selected methods to th e mybride expert tool in order this comparison was possible the structure of input data sets was reorganized to use the same datasets as the expert tool was tested on also root mean squared error rmse and mean absolute error mae are used to determine the quality of possible predictions the comparison between tested methods and the expert tool shows that only two out of five considered algorithms using non normalized input data give results that are similar to expert tool predictions these methods are fuzzy gap and thrift with mean rmse for all data sets respectively 12 4 and 7 1 whereas the reference rmse value is 3 5 presented results are very useful for planned implementation of intelligent tools for the bridge management systems 2010 taylor francis group london assessing object oriented software systems based on change impact simulation software changes are inevitable during software evolution and software change propagation intensely increases the difficulty of software maintenance in this paper we regard various change requirements as the combination of a series of atomic change requirement software modifications which are used to satisfy the atomic change requirement are considered as modifications of a random selected initial element and the ripple effects caused by the modifications then we propose a method for assessing the change propagation of object oriented software based on change impact simulation firstly the method to construct a software change propagation model and related software metric indicators are presented the rationale of this approach is that different strength of coupling has different probability of change propagation secondly an approach for getting the probability of change propagation setting is provided which is based on change history obtained from software version repositories and different dependence relationships finally the proposed systematic approach has been evaluated on a multi version medium sized open source object namely apache ant is a java based build tool which indicates the simplicity and rationality of our approach 2010 ieee change impact change propagation probability simulation approach software change using data mining in optimisation of building energy consumption and thermal comfort management performance monitoring using wireless sensors is now common practice in building operation and maintenance and generates a large amount of building specific data however it is difficult for occupants owners and operators to explore such data and understand underlying patterns this is especially true in buildings which involve complex interactions such as ventilation solar gains internal gains and thermal mass performance monitoring requires collecting data concerning energy consumption and ambient environmental conditions to model and optimise buildings energy consumption this paper details the use of data mining techniques in understanding building energy performance of geothermal solar and gas burning energy systems the paper is part of an outgoing research into optimisation of building performance under hybrid energy regimes the objective of the research presented in this paper is to predict comfort levels based on the heating ventilating and air conditioning hvac system performance and external environmental conditions a c4 5 classification methodology is used to analyse a combination of internal and external ambient conditions the mining algorithms are used to determine comfort constraints and the influence of external conditions on a building s internal user comfort to test the performance of classification and its use in prediction different offices one to the south and the other to the north of the building are used classification rules being developed are analysed for their application to modify control algorithms and to apply results to generalise hybrid system performance the results of this study can be generalised for an entire building or a set of buildings under a single energy network subject to the same constraints classification data mining energy hvac multidimension performance sensors applications of support vector mathine and unsupervised learning for predicting maintainability using object oriented metrics importance of software maintainability is increasing leading to development of new sophisticated techniques this paper presentes the applications of support vector machine and unsupervised learning in software maintainability prediction using object oriented metrics in this paper the software maintainability predictor is performed the dependent variable was maintenance effort the independent variable were five oo metrics decided clustering technique the results showed that the mean absolute relative error mare was 0 218 of the predictor therefore we found that svm and clustering technique were useful in constructing software maintainability predictor novel predictor can be used in the similar software developed in the same environment 2010 ieee maintainability object oriented metrics predict support vector machine unsupervised learning counselor a data mining based time estimation for software maintenance measuring and estimating are fundamental activities for the success of any project in the software maintenance realm the lack of maturity or even a low level of interest in adopting effective maintenance techniques and related metrics have been pointed out as an important cause for the high costs involved in this paper data mining techniques are applied to provide a sound estimation for the time required to accomplish a maintenance task based on real world data regarding maintenance requests some regression models are built to predict the time required for each maintenance data on the team skill and the maintenance characteristics are mapped into values that predict better time estimations in comparison to the one predicted by the human expert a particular finding from this research is that the time prediction provided by a human expert works as an inductive bias that improves the overall prediction accuracy 2009 springer berlin heidelberg data mining informal reasoning software maintenance an expert system for determining candidate software classes for refactoring in the lifetime of a software product development costs are only the tip of the iceberg nearly 90 of the cost is maintenance due to error correction adaptation and mainly enhancements as lehman and belady lehman m m belady l a 1985 program evolution processes of software change academic press professional state that software will become increasingly unstructured as it is changed one way to overcome this problem is refactoring refactoring is an approach which reduces the software complexity by incrementally improving internal software quality our motivation in this research is to detect the classes that need to be rafactored by analyzing the code complexity we propose a machine learning based model to predict classes to be refactored we use weighted naïve bayes with infogain heuristic as the learner and we conducted experiments with metric data that we collected from the largest gsm operator in turkey our results showed that we can predict 82 of the classes that need refactoring with 13 of manual inspection effort on the average 2008 elsevier ltd all rights reserved naive bayes refactor prediction refactoring software metrics application of treenet in predicting object oriented software maintainability a comparative study there is an increasing interest in more accurate prediction of software maintainability in order to better manage and control software maintenance recently treenet has been proposed as a novel advance in data mining that extends and improves the cart classification and regression trees model using stochastic gradient boosting this paper empirically investigates whether the treenet model yields improved prediction accuracy over the recently published object oriented software maintainability prediction models multivariate adaptive regression splines multivariate linear regression support vector regression artificial neural network and regression tree the results indicate that improved or at least competitive prediction accuracy has been achieved when applying the treenet model 2009 ieee using random test selection to gain confidence in modified software this paper presents a method that addresses two practical issues concerning the use of random test selection for regression testing the number of random samples needed from the test suite to provide reliable results and the confidence levels of the predictions made by the random samples the method applies the chernoff bound which has been applied in various randomized algorithms to compute the error bound for random test selection the paper presents three example applications based on the method for regression testing the main benefits of the method are that it requires no distribution information about the test suite from which the samples are taken and the computation of the confidence level is independent of the size of the test suite the paper also presents the results of an empirical evaluation of the technique on a set of c programs which have been used in many testing experiments along with three of the gcc compilers the results demonstrate the effectiveness of the method and show its potential for regression testing on real world large scale applications 2008 ieee optimal successive mappings for classification in this paper we propose a new method of designing and constructing good mappings defined by kernel functions for classification task called optimal successive mappings osm kernel methods such as support vector machines svm could not provide satisfactory classification accuracy on some complicated data sets which are still not linearly separable in feature space it means kernels designed only by tuning kernel parameters cannot adapt well to classification of complicated data sets unlike tuning parameters osm learns and designs its kernel from training data through a sequence of two mappings and optimizing a criteria function after feature mapping of osm data in the feature space appear not only linearly separable but also intra class compact and extra class separate as the problem of optimizing the criteria function reduces to a generalized eigenvalue problem osm possesses non iterative and low complex properties comparative experiments demonstrate the effectiveness of our method 2008 ieee data classification kernel methods kernel optimization prediction of maintainability using software complexity analysis an extended frt in this paper a method is proposed for predicting software maintainability prediction of maintainability of a product is done by using its code complexity here a sample of 4 products is taken into consideration and both the absolute and relative complexity assessment are made over it the process of measuring the code complexity is done at testing phase we employ the fuzzy repertory table frt technique to acquire the necessary domain knowledge of testers from which the software complexity analysis is made regression analysis is then used to predict maintainability from the product s code complexity 2008 ieee fuzzy repertory table regression analysis software maintainability trapezoid number aode for source code metrics for improved software maintainability software metrics are collected at various phases of the whole software development process in order to assist in monitoring and controlling the software quality however software quality control is complicated because of the complex relationship between these metrics and the attributes of a software development process to solve this problem many excellent techniques have been introduced into software maintainability domain in this paper we propose a novel classification method aggregating one dependence estimators aode to support and enhance our understanding of software metrics and their relationship to software quality experiments show that performance of aode is much better than eight traditional classification methods and it is a promising method for software quality prediction furthermore we present a symmetrical uncertainty su based feature selection method to reduce source code metrics taking part in classification make these classifiers more efficient and keep their performances not undermined meanwhile our empirical study shows the promising capability of su for selecting relevant metrics and preserving original performances of the classifiers 2008 ieee an overview and case study of a statistical regression testing method for software maintenance we propose a statistical regression testing method for evaluating the reliability of software as part of the software maintenance process maintenance procedures take up more than half the time of the software development process in addition software reliability is an important factor in determining the dependability of a product regression tests are performed in order to conserve or improve software reliability as part of the software maintenance process however existing systematic testing methods based on regression tests are not necessarily appropriate for evaluating software reliability the statistical regression testing method is a means for compensating for the flaws of such existing methods in this method a model of how the user makes use of the software is defined by means of a markov chain this is known as the usage model and then test cases are generated at random according to a probability distribution based on this usage model in this paper we perform experiments applying the proposed method to a small scale client server program and demonstrate that the proposed method can be implemented in addition we clarify the effects and issues that may be anticipated when applying the method and establish how it may be used in practice 2007 wiley periodicals inc automated tests markov chains regression tests software reliability evaluation statistical tests modification analysis support at the requirements level modification analysis is part of most maintenance processes and includes among other activities early prediction of potential change impacts feasibility studies cost estimation etc existing impact analysis and regression testing techniques being source code based require at least some understanding of the system implementation in this research we present a novel approach that combines ucm with fca to assist decision makers in supporting modification analysis at the requirements level our approach provides support for determining the potential modification and re testing effort associated with a change without the need to analyze or comprehend source code we demonstrate the applicability of our approach on a telephony system case study copyright 2007 acm change impact analysis formal concept analysis regression testing use case maps modification analysis support at the requirements level modification analysis is part of most maintenance processes and includes among other activities early prediction of potential change impacts feasibility studies cost estimation etc existing impact analysis and regression testing techniques being source code based require at least some understanding of the system implementation in this research we present a novel approach that combines ucm with fca to assist decision makers in supporting modification analysis at the requirements level our approach provides support for determining the potential modification and re testing effort associated with a change without the need to analyze or comprehend source code we demonstrate the applicability of our approach on a telephony system case study 2007 acm isbn change impact analysis formal concept analysis regression testing use case maps a model to predict anti regressive effort in open source software accumulated changes on a software system are not uniformly distributed some elements are changed more often than others for optimal impact the limited time and effort for complexity control called anti regressive work should be applied to the elements of the system which are frequently changed and are complex based on this we propose a maintenance guidance model mgm which is tested against real world data mgm takes into account several dimensions of complexity size structural complexity and coupling results show that maintainers of the eight open source systems studied tend in general to prioritize their anti regressive work in line with the predictions given by our mgm even though divergences also exist mgm offers a history based alternative to existing approaches to the identification of elements for anti regressive work most of which use static code characteristics only 2007 ieee anti regressive work coupling empirical studies maintenance mccabe cyclomatic complexity metrics open source software evolution predicting object oriented software maintainability using multivariate adaptive regression splines accurate software metrics based maintainability prediction can not only enable developers to better identify the determinants of software quality and thus help them improve design or coding it can also provide managers with useful information to help them plan the use of valuable resources in this paper we employ a novel exploratory modeling technique multiple adaptive regression splines mars to build software maintainability prediction models using the metric data collected from two different object oriented systems the prediction accuracy of the mars models are evaluated and compared using multivariate linear regression models artificial neural network models regression tree models and support vector models the results suggest that for one system mars can predict maintainability more accurately than the other four typical modeling techniques and that for the other system mars is as accurate as the best modeling technique 2006 elsevier inc all rights reserved maintainability multiple adaptive regression splines object oriented prediction life cycle management distributed web based software development with evolutionary programming and stochastic optimization this article is an extension of the work presented earlier which compared and analyzed the economics of alternative maintenance plans the previous approach has been improved by an application of a genetic algorithm the system is introduced as a distributed web based software application the methodology based on combining evolutionary programming with monte carlo simulations is described and illustrated by a numerical example involving analysis of the optimal timing of new investments for refurbishment of a large steam generating unit copyright kth 2006 evolutionary algorithms genetic algorithms life cycle management stochastic optimization an application of bayesian network for predicting object oriented software maintainability as the number of object oriented software systems increases it becomes more important for organizations to maintain those systems effectively however currently only a small number of maintainability prediction models are available for object oriented systems this paper presents a bayesian network maintainability prediction model for an object oriented software system the model is constructed using object oriented metric data in li and henry s datasets which were collected from two different object oriented systems prediction accuracy of the model is evaluated and compared with commonly used regression based models the results suggest that the bayesian network model can predict maintainability more accurately than the regression based models for one system and almost as accurately as the best regression based model for the other system 2005 elsevier b v all rights reserved bayesian network maintainability object oriented systems regression regression tree quantifying software architectures an analysis of change propagation probabilities software architectures are an emerging discipline in software engineering as they play a central role in many modern software development paradigms quantifying software architectures is an important research agenda as it allows software architects to subjectively assess quality attributes and rationalize architecture related decisions in this paper we discuss the attribute of change propagation probability which reflects the likelihood that a change that arises in one component of the architecture propagates i e mandates changes to other components 2005 ieee change propagation probability software architectures software engineering software maintenance software metrics maintainability prediction a regression analysis of measures of evolving systems in order to build predictors of the maintainability of evolving software we first need a means for measuring maintainability as well as a training set of software modules for which the actual maintainability is known this paper describes our success at building such a predictor numerous candidate measures for maintainability were examined including a new compound measure two datasets were evaluated and used to build a maintainability predictor the resulting model maintainability prediction model mainpredmo was validated against three held out datasets we found that the model possesses predictive accuracy of 83 accurately predicts the maintainability of 83 of the modules a variant of mainpredmo also with accuracy of 83 is offered for interested researchers 2005 ieee predicting the probability of change in object oriented systems of all merits of the object oriented paradigm flexibility is probably the most important in a world of constantly changing requirements and the most striking difference compared to previous approaches however it is rather difficult to quantify this aspect of quality this paper describes a probabilistic approach to estimate the change proneness of an object oriented design by evaluating the probability that each class of the system will be affected when new functionality is added or when existing functionality is modified it is obvious that when a system exhibits a large sensitivity to changes the corresponding design quality is questionable the extracted probabilities of change can be used to assist maintenance and to observe the evolution of stability through successive generations and identify a possible saturation level beyond which any attempt to improve the design without major refactoring is impossible the proposed model has been evaluated on two multiversion open source projects the process has been fully automated by a java program while statistical analysis has proved improved correlation between the extracted probabilities and actual changes in each of the classes in comparison to a prediction model that relies simply on past data 2005 ieee object oriented design methods object oriented programming product metrics quality analysis and evaluation assessing effort estimation models for corrective maintenance through empirical studies we present an empirical assessment and improvement of the effort estimation model for corrective maintenance adopted in a major international software enterprise our study was composed of two phases in the first phase we used multiple linear regression analysis to construct effort estimation models validated against real data collected from five corrective maintenance projects the model previously adopted by the subject company used as predictors the size of the system being maintained and the number of maintenance tasks while this model was not linear we show that a linear model including the same variables achieved better performances also we show that greater improvements in the model performances can be achieved if the types of the different maintenance tasks is taken into account in the second phase we performed a replicated assessment of the effort prediction models built in the previous phase on a new corrective maintenance project conducted by the subject company on a software system of the same type as the systems of the previous maintenance projects the data available for the new project were finer grained according to the indications devised in the first study this allowed to improve the confidence in our previous empirical analysis by confirming most of the hypotheses made the new data also provided other useful indications to better understand the maintenance process of the company in a quantitative way 2004 elsevier b v all rights reserved corrective software maintenance cost estimation models experimentation management measurement a model for corrective maintenance time prediction using neural network this paper presents the application of neural networks in predicting corrective maintenance time the paper aims to establish the viability of the usage of feedforward artificial neural network for predicting the time needed to correct errors associated with changes made to the software during maintenance for this purpose a neural model using four software measures is proposed the software measures used are complexity measures like cyclomatic complexity acc readability of source code rsc documentation quality doq and understandability of software uos the neural network used is sigmoidal feedforward artificial neural network it is found that the neural network of the type used can act as an efficient predictor of corrective maintenance time corrective maintenance sffanns software measures modelling the process of incoming problem reports on released software products for big software developing companies it is important to know the amount of problems of a new software product that are expected to be reported in a period after the date of release on a weekly basis for each of a number of past releases weekly data are present on the number of such reports based on the type of data that is present we construct a stochastic model for the weekly number of problems to be reported the non parametric maximum likelihood estimator for the crucial model parameter the intensity of an inhomogeneous poisson process is defined moreover the expectation maximization algorithm is described which can be used to compute this estimate the method is illustrated using simulated data copyright 2004 john wiley sons ltd corrective software maintenance em algorithm inhomogeneous poisson process isotonic regression unimodality an information theory approach to studying software evolution information theory defines and mathematically characterizes several entropy measures including the well known shannon entropy based on these mathematical characterizations this paper rigorously chooses the entropy metrics which are suitable for measuring the information content of software systems by treating a software system as an information source the probabilities required for computing the entropy metrics are obtained using an empirical distribution of the symbols emitted from the source a preliminary case study is performed on a well known compiler implemented in a procedural programming language the results of the study validate the utility of the proposed metrics as indicators of software information content the metrics also represent a family of measures which satisfies different measurement requirements a second case study is performed on an object oriented graphics and multimedia software in addition to further validating the metrics the case study demonstrates their use in monitoring the evolution of a large software system it is shown that studying the evolution of the modules within the system reveals the different module behaviors that are concealed when the full system is viewed at the top level this understanding can be very useful to maintenance engineers because it guides them to the modules that undergo considerable information changes entropy information theory software engineering software evolution software maintenance software metrics determinants of software volatility a field study although technology advances have provided new tools for maintaining software maintenance costs remain the largest component of software life cycle cost a basic factor claimed to be one of the driving factors in the cost of maintenance is software volatility the objective of this research is to investigate the relationship between certain software attributes and software volatility in this study software volatility refers to the frequency or number of enhancements per unit of application over a specified time normalized however this metric is divided by the number of source lines of code sloc to obtain a measure that takes into account the size of the software application the research model is built on previous research concerning software volatility three factors are examined to determine their influence on software volatility normalized for sloc age software complexity and software complexity normalized for sloc in addition we introduce the notion that mean time between software enhancements moderates the relationship of age complexity and complexity normalized for sloc with software volatility a field study at a major corporation allowed for the collection of data from a 13 year time period these data are used to empirically test the hypotheses presented in this study as a moderator variable mean time between enhancements significantly contributes to the explanatory power of a prediction model for software volatility adjusted for sloc software administrators may wish to use the proposed model in their decision making plans to control for software costs copyright 2003 john wiley sons ltd development costs lines of code maintenance costs software metrics software quality software volatility an analogy based approach for predicting design stability of java classes 2003 ieee predicting stability in object oriented oo software i e the ease with which a software item evolves while preserving its design is a key feature for software maintenance in fact a well designed oo software must be able to evolve without violating the compatibility among versions provided that no major requirement reshuffling occurs stability like most quality factors is a complex phenomenon and its prediction is a real challenge we present an approach which relies on the case based reasoning cbr paradigm and thus overcomes the handicap of insufficient theoretical knowledge on stability the approach explores structural similarities between classes expressed as software metrics to guess their chances of becoming unstable in addition our stability model binds its value to the impact of changing requirements i e the degree of class responsibilities increase between versions quantified as the stress factor as a result the prediction mechanism favours the stability values for classes having strong structural analogies with a given test class as well as a similar stress impact our predictive model is applied on a testbed made up of the classes from four major version of the java api java object oriented modeling predictive models q factor software design software maintenance software metrics stability stress testing effort estimation for corrective software maintenance this paper reports on an empirical study aiming at constructing cost estimation models for corrective maintenance projects data available were collected from five maintenance projects currently carried out by a large software enterprise the resulting models constructed using multivariate linear regression techniques allow to estimate the costs of a project conducted according to the adopted maintenance processes model performances on future observations were achieved by taking into account different corrective maintenance task typologies each affecting the effort in a different way and assessed by means of a cross validation which guarantees a nearly unbiased estimate of the prediction error the constructed models are currently adopted by the subject company copyright 2002 acm d 2 8 software engineering management software maintenance cost estimation experimentation management measurement association analysis of software measures software measures metrics provide software engineers with an important means of quantifying essential features of software products and software processes such as software reliability maintenance reusability and alike software measures interact between themselves some of them may be deemed redundant software measures are used to construct detailed prediction models the objective of this study is to pursue an association analysis of software measures by revealing dependencies associations between them more specifically the introduced association analysis is carried out at the local level by studying dependencies between information granules of the software measures this approach is contrasted with a global level such as e g regression analysis we discuss the role of information granules as meaningful conceptual entities that facilitate analysis and give rise to a user friendly highly transparent environment associations fuzzy sets information granules rule based models rules software measures using code metrics to predict maintenance of legacy programs a case study this paper presents an empirical study on the correlation of simple code metrics and maintenance necessities the goal of the work is to provide a method for the estimation of maintenance in the initial stages of outsourcing maintenance projects when the maintenance contract is being prepared and there is very little available information on the software to be maintained the paper shows several positive results related with the mentioned goal code metrics maintenance prediction outsourcing modeling development effort in object oriented systems using design properties in the context of software cost estimation system size is widely taken as a main driver of system development effort but other structural design properties such as coupling cohesion and complexity have been suggested as additional cost factors in this paper using effort data from an object oriented development project we empirically investigate the relationship between class size and the development effort for a class and what additional impact structural properties such as class coupling have on effort this paper proposes a practical repeatable and accurate analysis procedure to investigate relationships between structural properties and development effort this is particularly important as it is necessary as for any empirical study to be able to replicate the analysis reported here more specifically we use poisson regression and regression trees to build cost prediction models from size and design measures and use these models to predict system development effort we also investigate a recently suggested technique to combine regression trees with regression analysis which aims at building more accurate models results indicate that fairly accurate predictions of class effort can be made based on simple measures of the class interface size alone mean mres below 30 percent effort predictions at the system level are even more accurate as using bootstrapping the estimated 95 percent confidence interval for mres is 3 to 23 percent but more sophisticated coupling and cohesion measures do not help to improve these predictions to a degree that would be practically significant however the use of hybrid models combining poisson regression and cart regression trees clearly improves the accuracy of the models as compared to using poisson regression alone cost estimation empirical validation object oriented measurement empirical studies of a prediction model for regression test selection regression testing is an important activity that can account for a large proportion of the cost of software maintenance one approach to reducing the cost of regression testing is to employ a selective regression testing technique that 1 chooses a subset of a test suite that was used to test the software before the modifications then 2 uses this subset to test the modified software selective regression testing techniques reduce the cost of regression testing if the cost of selecting the subset from the test suite together with the cost of running the selected subset of test cases is less than the cost of rerunning the entire test suite rosenblum and weyuker recently proposed coverage based predictors for use in predicting the effectiveness of regression test selection strategies using the regression testing cost model of leung and white rosenblum and weyuker demonstrated the applicability of these predictors by performing a case study involving 31 versions of the kornshell to further investigate the applicability of the rosenblum weyuker rw predictor additional empirical studies have been performed the rw predictor was applied to a number of subjects using two different selective regression testing tools dejavu and testtube these studies support two conclusions first they show that there is some variability in the success with which the predictors work and second they suggest that these results can be improved by incorporating information about the distribution of modifications it is shown how the rw prediction model can be improved to provide such an accounting regression test selection regression testing selective retest software maintenance maintainability model for industrial software systems using design level metrics software maintenance is a time consuming and expensive phase of a software product s life cycle this paper investigates the use of software design metrics to statistically estimate the maintainability of large software systems and to identify error prone modules a methodology for assessing evaluating and selecting software metrics for predicting software maintainability is presented in addition a linear prediction model based on a minimal set of design level software metrics is proposed the model is evaluated by applying it to industrial software systems software quality maintenance model we develop a quality control and prediction model for improving the quality of software delivered by development to maintenance this model identifies modules that require priority attention during development and maintenance the model also predicts during development the quality that will be delivered to maintenance we show that it is important to perform a marginal analysis when making a decision about how many metrics to include in a discriminant function if many metrics are added at once the contribution of individual metrics is obscured also the marginal analysis provides an effective rule for deciding when to stop adding metrics we also show that certain metrics are dominant in their effects on classifying quality and that additional metrics are not needed to increase the accuracy of classification data from the space shuttle flight software are used to illustrate the model process an examination of the effects of requirements changes on software maintenance releases requirements are the foundation of the software release process they provide the basis for estimating costs and schedules as well as developing design and testing specifications when requirements have been agreed on by both clients and maintenance management then adding to deleting from or modifying those existing requirements during the execution of the software maintenance process impacts the maintenance cost schedule and quality of the resulting product the basic problem is not the changing in itself but rather the inadequate approaches for dealing with changes in a way that minimizes and communicates the impact to all stakeholders using data collected from one organization on 44 software releases spanning seven products this paper presents two quantitative techniques for dealing with requirements change in a maintenance environment first exploratory data analysis helps one to understand the sources frequency and types of changes being made second a regression model helps managers communicate the cost and schedule effects of changing requirements to clients and other release stakeholders these two techniques can help an organization provide a focus for management action during the software maintenance process copyright 1999 john wiley sons ltd maintenance productivity maintenance release management requirements taxonomy requirements volatility risk schedule prediction code decay analysis of legacy software through successive releases prediction of problematic software components is an important activity today for many organizations as they manage their legacy systems and the maintenance problems they cause this means that there is a need for methods and models to identify troublesome components we apply a model for classification of software components as green yellow and red according to the number of times they required corrective maintenance over successive releases further we apply a principal component and box plot analysis to investigate the causes for the code decay and try to characterize the releases the case study includes eight releases and 130 software components the outcome indicates a large number of healthy components as well as a small set of troublesome components requiring extensive repair repeatedly the analysis characterizes the releases and indicates that it is the relationship between components that causes many of the problems methods of measuring software reuse for the prediction of maintenance effort a major difficulty in evaluating the costs of reusing software is determining the amount of reused software artefacts in systems determining the amount of reuse in a system is important for software maintenance because reused software is likely to need less corrective maintenance than newly developed software reusing software can also decrease costs of testing and integration in this paper we describe some practical techniques for measuring the amount of software reuse using simple tools the goal is to provide accurate assessment of the state of existing software systems in order to assess quality and deploy resources efficiently the techniques for software developed on the unix system use the standard utilities find and diff software developed under configuration management by the sees utility is measured using the prs utility techniques are also given for measurement of the amount of reuse in software that was developed on personal computers each of the methods was used for reuse measurement at nasa s goddard space flight center the methods were applied to measure reuse in moderately large software systems used for ground centre control of spacecraft configuration management cots reuse categories reuse factors software metrics software reuse experience with the accuracy of software maintenance task effort prediction models this paper reports experience from the development and use of eleven different software maintenance effort prediction models the models were developed applying regression analysis neural networks and pattern recognition and the prediction accuracy was measured and compared for each model type the most accurate predictions were achieved applying models based on multiple regression and on pattern recognition we suggest the use of prediction models as instruments to support the expert estimates and to analyse the impact of the maintenance variables on the maintenance process and product we believe that the pattern recognition based models evaluated i e the prediction models based on the optimized set reduction method show potential for such use 1995 ieee cost models neural network pattern recognition prediction models regression software maintenance software measurement object oriented metrics that predict maintainability software metrics have been studied in the procedural paradigm as a quantitative means of assessing the software development process as well as the quality of software products several studies have validated that various metrics are useful indicators of maintenance effort in the procedural paradigm however software metrics have rarely been studied in the object oriented paradigm very few metrics have been proposed to measure object oriented systems and the proposed ones have not been validated this research concentrates on several object oriented software metrics and the validation of these metrics with maintenance effort in two commercial systems statistical analyses of a prediction model incorporating 10 metrics were performed in addition a more compact model with fewer metrics is presented 1993